<!DOCTYPE html>
<html lang="zh-cn">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>一些在Jetson设备的开发经验 | 指尖魔法屋</title>

    
    <meta name="description" content="NVIDIA Jetson系列设备作为边缘AI计算的重要平台，在计算机视觉和深度学习应用中发挥着关键作用。本文将详细介绍Jetson设备的刷机、SDK安装、YOLO模型部署以及TensorRT优化等开发经验，帮助开发者快速上手并实现高性能的AI应用部署。">
    <meta name="keywords" content="Jetson, 深度学习, YOLO, TensorRT">

    
    <meta property="og:title" content="一些在Jetson设备的开发经验">
    <meta property="og:description" content="NVIDIA Jetson系列设备作为边缘AI计算的重要平台，在计算机视觉和深度学习应用中发挥着关键作用。本文将详细介绍Jetson设备的刷机、SDK安装、YOLO模型部署以及TensorRT优化等开发经验，帮助开发者快速上手并实现高性能的AI应用部署。">
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://example.org/post/989_%E4%B8%80%E4%BA%9B%E5%9C%A8jetson%E8%AE%BE%E5%A4%87%E7%9A%84%E5%BC%80%E5%8F%91%E7%BB%8F%E9%AA%8C/">
    

    
    <link rel="icon" href="https://example.org/favicon.ico">

    
    <link rel="stylesheet" href="/css/reset.css">
    <link rel="stylesheet" href="/css/github-markdown.css">
    <link rel="stylesheet" href="/css/custom.css">
</head>
<body>
    
    
    <nav class="top-menu">
        <div class="container">
            <div class="left">
                <a href="https://example.org/">指尖魔法屋</a>
            </div>
            <ul class="menu">
                <li class="">
                    <a href="https://example.org/">首页</a>
                </li>
                <li class="">
                    <a href="https://example.org/categories/">分类</a>
                </li>
                <li class="">
                    <a href="https://example.org/tags/">标签</a>
                </li>
            </ul>
            <div class="right">
                <a href="/admin" class="admin-link">
                    <span>登录</span>
                </a>
            </div>
        </div>
    </nav>
    

    
    <main>
        
<div class="article-content">
    <div class="markdown-body">
        <h1 id="一些在jetson设备的开发经验">一些在Jetson设备的开发经验</h1>
<blockquote>
<p>NVIDIA Jetson系列设备作为边缘AI计算的重要平台，在计算机视觉和深度学习应用中发挥着关键作用。本文将详细介绍Jetson设备的刷机、SDK安装、YOLO模型部署以及TensorRT优化等开发经验，帮助开发者快速上手并实现高性能的AI应用部署。</p>
</blockquote>
<h2 id="一jetson设备概述">一、Jetson设备概述</h2>
<h3 id="11-什么是nvidia-jetson">1.1 什么是NVIDIA Jetson？</h3>
<p>NVIDIA Jetson是一系列基于ARM架构的嵌入式AI计算平台，专为边缘计算和机器人应用设计。Jetson设备集成了高性能的GPU、CPU和深度学习加速器，能够在低功耗环境下运行复杂的AI模型。</p>
<h3 id="12-jetson系列对比">1.2 Jetson系列对比</h3>
<table>
<thead>
<tr>
<th>设备型号</th>
<th>GPU</th>
<th>CPU</th>
<th>内存</th>
<th>功耗</th>
<th>适用场景</th>
</tr>
</thead>
<tbody>
<tr>
<td>Jetson AGX Orin (64GB)</td>
<td>2048-core Ampere</td>
<td>12-core Arm Cortex-A78AE</td>
<td>64GB LPDDR5</td>
<td>60W</td>
<td>高性能AI推理</td>
</tr>
<tr>
<td>Jetson Orin NX 16GB</td>
<td>1024-core Ampere</td>
<td>8-core Arm Cortex-A78AE</td>
<td>16GB LPDDR5</td>
<td>25W</td>
<td>中等性能应用</td>
</tr>
<tr>
<td>Jetson Orin Nano</td>
<td>1024-core Ampere</td>
<td>6-core Arm Cortex-A78AE</td>
<td>8GB LPDDR5</td>
<td>15W</td>
<td>入门级AI应用</td>
</tr>
</tbody>
</table>
<h2 id="二jetpack-sdk安装与配置">二、JetPack SDK安装与配置</h2>
<h3 id="21-什么是nvidia-jetpack">2.1 什么是NVIDIA JetPack？</h3>
<p>JetPack是NVIDIA为Jetson设备提供的软件开发套件，包含了完整的操作系统、CUDA、cuDNN、TensorRT等深度学习框架和工具链。</p>
<h3 id="22-刷机步骤">2.2 刷机步骤</h3>
<h4 id="221-准备工作">2.2.1 准备工作</h4>
<ul>
<li>下载JetPack SDK Manager</li>
<li>准备USB线缆和电源适配器</li>
</ul>
<h4 id="222-刷机流程">2.2.2 刷机流程</h4>
<ol>
<li>
<p><strong>下载JetPack SDK Manager</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="c1"># 从NVIDIA官网下载对应版本的SDK Manager</span>
</span></span></code></pre></div></li>
<li>
<p><strong>启动SDK Manager</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="c1"># 在Ubuntu主机上运行</span>
</span></span><span class="line"><span class="cl">sudo ./sdkmanager
</span></span></code></pre></div><p>如果有图形化界面就直接双击运行</p>
</li>
<li>
<p><strong>选择目标设备</strong></p>
<ul>
<li>选择对应的Jetson设备型号（连上usb数据线时，会自动检测对应的型号）</li>
<li>选择JetPack版本（推荐6.1）</li>
<li>选择安装组件，必选cuda，否则后续自行安装会很麻烦。时间充裕时，可选择全部SDK</li>
</ul>
</li>
<li>
<p><strong>刷写系统</strong></p>
<ul>
<li>如果能够进入系统，可直接执行<code>sudo reboot –force forced-recovery</code>。若是无法进入系统（刷机失败的情况下）可通过短接进入恢复模式。</li>
<li>判断恢复模式是否进入成功，可以在SDK Manager上查看对应jetson status</li>
<li>然后执行flash，如果使用sdk manager可视化刷机失败。可通过命令行进行刷机。</li>
</ul>
</li>
</ol>
<h3 id="23-首次启动配置">2.3 首次启动配置</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="c1"># 启用最大性能模式</span>
</span></span><span class="line"><span class="cl">sudo nvpmodel -m <span class="m">0</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 启用Jetson时钟</span>
</span></span><span class="line"><span class="cl">sudo jetson_clocks
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 安装jetson-stats监控工具</span>
</span></span><span class="line"><span class="cl">sudo apt update
</span></span><span class="line"><span class="cl">sudo pip install jetson-stats
</span></span><span class="line"><span class="cl">sudo reboot
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 启动监控界面</span>
</span></span><span class="line"><span class="cl">jtop
</span></span></code></pre></div><h2 id="三深度学习环境配置">三、深度学习环境配置</h2>
<h3 id="31-pytorch安装">3.1 PyTorch安装</h3>
<h4 id="311-卸载现有版本">3.1.1 卸载现有版本</h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="c1"># 卸载可能存在的PyTorch版本</span>
</span></span><span class="line"><span class="cl">pip uninstall torch torchvision
</span></span></code></pre></div><h4 id="312-安装arm64兼容版本pytorch-和-torchvision">3.1.2 安装ARM64兼容版本PyTorch 和 Torchvision</h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="c1"># 对于JetPack 6.1</span>
</span></span><span class="line"><span class="cl">pip install https://github.com/ultralytics/assets/releases/download/v0.0.0/torch-2.5.0a0+872d972e41.nv24.08-cp310-cp310-linux_aarch64.whl
</span></span><span class="line"><span class="cl">pip install https://github.com/ultralytics/assets/releases/download/v0.0.0/torchvision-0.20.0a0+afc54f7-cp310-cp310-linux_aarch64.whl
</span></span></code></pre></div><blockquote>
<p>注意事项：请勿直接通过pip安装，通过 pip 安装的这两个包与基于 ARM64 架构的 Jetson 平台不兼容。因此，我们需要手动安装预构建的 PyTorch pip wheel 并从源代码编译/安装 Torchvision</p>
</blockquote>
<h3 id="32-安装ultralytics-yolo">3.2 安装Ultralytics YOLO</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="c1"># 安装Ultralytics包</span>
</span></span><span class="line"><span class="cl">pip install ultralytics
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 验证安装</span>
</span></span><span class="line"><span class="cl">python -c <span class="s2">&#34;import ultralytics; print(&#39;YOLO安装成功&#39;)&#34;</span>
</span></span></code></pre></div><h3 id="33-安装onnx-runtime-gpu">3.3 安装ONNX Runtime GPU</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">pip install https://github.com/ultralytics/assets/releases/download/v0.0.0/onnxruntime_gpu-1.20.0-cp310-cp310-linux_aarch64.whl
</span></span></code></pre></div><blockquote>
<p>YOLO官网上说要安装gpu版本的，但是我发现直接使用jetson的onnxruntime默认就支持了GPU</p>
</blockquote>
<h2 id="四yolo模型部署与优化">四、YOLO模型部署与优化</h2>
<h3 id="41-基础yolo推理">4.1 基础YOLO推理</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">ultralytics</span> <span class="kn">import</span> <span class="n">YOLO</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 加载预训练模型</span>
</span></span><span class="line"><span class="cl"><span class="n">model</span> <span class="o">=</span> <span class="n">YOLO</span><span class="p">(</span><span class="s2">&#34;yolo11n.pt&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 运行推理</span>
</span></span><span class="line"><span class="cl"><span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="s2">&#34;path/to/image.jpg&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 显示结果</span>
</span></span><span class="line"><span class="cl"><span class="n">results</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span></code></pre></div><h3 id="42-模型格式转换">4.2 模型格式转换</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">ultralytics</span> <span class="kn">import</span> <span class="n">YOLO</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Load a YOLO11n PyTorch model</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">model</span> <span class="o">=</span> <span class="n">YOLO</span><span class="p">(</span><span class="s2">&#34;yolo11n.pt&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Export the model to TensorRT</span>
</span></span><span class="line"><span class="cl"><span class="n">model</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="nb">format</span><span class="o">=</span><span class="s2">&#34;engine&#34;</span><span class="p">,</span> <span class="n">half</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># creates &#39;yolo11n.engine&#39;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Load the exported TensorRT model</span>
</span></span><span class="line"><span class="cl"><span class="n">trt_model</span> <span class="o">=</span> <span class="n">YOLO</span><span class="p">(</span><span class="s2">&#34;yolo11n.engine&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Run inference</span>
</span></span><span class="line"><span class="cl"><span class="n">results</span> <span class="o">=</span> <span class="n">trt_model</span><span class="p">(</span><span class="s2">&#34;https://ultralytics.com/images/bus.jpg&#34;</span><span class="p">)</span>
</span></span></code></pre></div><p>该命令会自动下载对应的yolo模型，并进行tensorrt编译导出。</p>
<h2 id="五常见问题与解决方案">五、常见问题与解决方案</h2>
<h3 id="51-安装问题">5.1 安装问题</h3>
<p><strong>问题：PyTorch安装失败</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="c1"># 解决方案：使用预编译的wheel包</span>
</span></span><span class="line"><span class="cl">pip install <span class="nv">torch</span><span class="o">==</span>1.13.0+cu117 <span class="nv">torchvision</span><span class="o">==</span>0.14.0+cu117 --index-url https://download.pytorch.org/whl/cu117
</span></span></code></pre></div><p><strong>问题：CUDA版本不匹配</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="c1"># 检查CUDA版本</span>
</span></span><span class="line"><span class="cl">nvcc --version
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 安装对应版本的PyTorch</span>
</span></span><span class="line"><span class="cl">pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121
</span></span></code></pre></div><h3 id="72-性能问题">7.2 性能问题</h3>
<p><strong>问题：推理速度慢</strong></p>
<ul>
<li>启用最大性能模式：<code>sudo nvpmodel -m 0</code></li>
<li>使用TensorRT优化：<code>model.export(format=&quot;engine&quot;)</code></li>
<li>启用FP16精度：<code>half=True</code></li>
</ul>
<p><strong>问题：conda环境无法识别tensorrt，提示moudle not found</strong>
这是因为jetson内嵌tensorrt，但是conda环境没有对应的path。可通过增加环境变量，如：</p>
<pre tabindex="0"><code>PYTHONPATH=&#34;/usr/lib/python3.10/dist-packages:$PYTHONPATH&#34; python yolo-export.py
# &#34;/usr/lib/python3.10/dist-packages&#34;这个路径为系统内置python的路径。
</code></pre><p><strong>问题：pytorch运行报错</strong></p>
<p>可能是因为pytorch版本大于24.06，此时需要安装一个稀疏矩阵乘加速的库<code> cusparselt</code></p>
<pre tabindex="0"><code>wget 
raw.githubusercontent.com/pytorch/pytorch/5c6af2b583709f6176898c017424dc9981023c28/.ci/docker/
common/install_cusparselt.sh 
export CUDA_VERSION=12.1 # as an example   
bash ./install_cusparselt.sh
</code></pre><h2 id="参考文献">参考文献</h2>
<ol>
<li><a href="https://docs.ultralytics.com/zh/guides/nvidia-jetson/">Ultralytics YOLO官方文档 - NVIDIA Jetson指南</a></li>
<li><a href="https://docs.nvidia.com/deeplearning/frameworks/install-pytorch-jetson-platform/index.html">NVIDIA深度学习框架安装指南 - PyTorch Jetson平台</a></li>
<li><a href="https://jetsonhacks.com/jetson-specific-commands/">JetsonHacks - Jetson特定命令参考</a></li>
<li><a href="https://developer.nvidia.com/embedded/jetson-linux">NVIDIA Jetson开发者文档</a></li>
<li><a href="https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html">TensorRT开发者指南</a></li>
</ol>

    </div>

    
    <ins class="adsbygoogle"
         style="display:block; text-align:center;width: 100%"
         data-ad-client="ca-pub-3208634444966567"
         data-ad-format="fluid"
         data-ad-layout="in-article"
         data-ad-slot="2621880404">
    </ins>
</div>

    </main>

    
    <footer class="footer">
        <div class="container">
            <span>Copyright © 2017-2025 指尖魔法屋. All rights reserved</span>
            <span>POWERED BY thinkBlog · v1.0.0</span>
            <span>网站持续搭建中，感谢关注</span>
            <div class="beian">
                <a href="http://beian.miit.gov.cn/" target="_blank">粤ICP备17055617号</a>
            </div>
        </div>
    </footer>

    
    <script src="https://example.org/js/thinkblog.js"></script>
</body>
</html>
